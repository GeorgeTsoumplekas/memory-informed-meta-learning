{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsoump/memory-informed-meta-learning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import load_inp_model, load_memory_inp_model, get_mask\n",
    "import sys\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import json\n",
    "\n",
    "from dataset.dataset import *\n",
    "from dataset.utils import get_dataloader\n",
    "from evaluation.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Dark2\")\n",
    "\n",
    "plt.rcParams[\"text.latex.preamble\"] = (\n",
    "    \"\\\\usepackage{lmodern} \\\\usepackage{times} \\\\usepackage{amssymb}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "save_dirs = {\n",
    "    \"NP\": \"../saves/INPs_sinusoids/np_0\",\n",
    "    \"INP\": \"../saves/INPs_sinusoids/inp_abc2_0\",\n",
    "    \"MemoryINP\": \"../saves/INPs_sinusoids/memory_inp_abc2_0\",\n",
    "}\n",
    "\n",
    "models = list(save_dirs.keys())\n",
    "model_dict = {}\n",
    "config_dict = {}\n",
    "\n",
    "for model_name, save_dir in save_dirs.items():\n",
    "    if model_name == \"MemoryINP\":\n",
    "        model_dict[model_name], config_dict[model_name] = load_memory_inp_model(\n",
    "            save_dir, load_it=\"best\"\n",
    "        )\n",
    "    else:\n",
    "        model_dict[model_name], config_dict[model_name] = load_inp_model(\n",
    "            save_dir, load_it=\"best\"\n",
    "        )\n",
    "    model_dict[model_name].eval()\n",
    "\n",
    "model_names = list(model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataloaders\n",
    "config = Namespace(\n",
    "    min_num_context=0,\n",
    "    max_num_context=100,\n",
    "    num_targets=100,\n",
    "    noise=0.2,\n",
    "    batch_size=32,\n",
    "    x_sampler=\"uniform\",\n",
    "    test_num_z_samples=32,\n",
    "    dataset=\"set-trending-sinusoids\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "dataset = SetKnowledgeTrendingSinusoids(\n",
    "    root=\"../data/trending-sinusoids\", split=\"test\", knowledge_type=\"full\"\n",
    ")\n",
    "data_loader = get_dataloader(dataset, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Important**: Due to lack of memory of VRAM (8gb available) I have to compute the summary_df table in two steps:\n",
    "1. Compute the summary_df table for smaller context sets [0, 1, 3, 5, 10, 15]\n",
    "2. Compute the summary_df table for larger context sets [30, 50, 100]\n",
    "\n",
    "To do this: \n",
    "\n",
    "1. First uncomment the first num_context_ls and the corresponding .to_csv() lines and run the cell.\n",
    "2. Then restart kernel and run the cell again with the second num_context_ls uncommented and the corresponding .to_csv() lines.\n",
    "3. After that continue with the rest of the code that combines the two saved summary_df into a unified one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models on different knowledge types\n",
    "eval_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"bc\", \"ac\"]\n",
    "\n",
    "# 1st run\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "\n",
    "# # 2nd run\n",
    "# num_context_ls = [30, 50, 100]\n",
    "\n",
    "if not os.path.exists(\"./artifacts\"):\n",
    "    os.makedirs(\"./artifacts\")\n",
    "\n",
    "\n",
    "summary_df, losses, outputs_dict = get_summary_df(\n",
    "    model_dict, config_dict, data_loader, eval_type_ls, model_names, num_context_ls\n",
    ")\n",
    "\n",
    "summary_df[\"print_value\"] = summary_df[\"mean\"].apply(\n",
    "    lambda x: f\"{x:.1f}\"\n",
    ")\n",
    "print_df = (\n",
    "    summary_df.dropna(subset=[\"mean\"])\n",
    "    .pivot(\n",
    "        columns=\"num_context\", index=[\"model_name\", \"eval_type\"], values=[\"print_value\"]\n",
    "    )\n",
    "    .T.round(2)\n",
    ")\n",
    "\n",
    "# Convert losses to a format that can be serialized to JSON\n",
    "losses_json = {}\n",
    "for model_name, model_losses in losses.items():\n",
    "    losses_json[model_name] = {}\n",
    "    for eval_type, eval_losses in model_losses.items():\n",
    "        losses_json[model_name][eval_type] = {}\n",
    "        for num_context, context_losses in eval_losses.items():\n",
    "            # Convert tensor lists to regular lists of floats\n",
    "            losses_json[model_name][eval_type][num_context] = [\n",
    "                loss.cpu().numpy().tolist() for loss in context_losses\n",
    "            ]\n",
    "\n",
    "# 1st run\n",
    "print_df.to_csv(\"./artifacts/small_context_print_df.csv\", index=False)\n",
    "summary_df.to_csv(\"./artifacts/small_context_summary_df.csv\", index=False)\n",
    "loss_file = \"./artifacts/small_context_losses.json\"\n",
    "\n",
    "# # 2nd run\n",
    "# print_df.to_csv(\"./artifacts/large_context_print_df.csv\", index=False)\n",
    "# summary_df.to_csv(\"./artifacts/large_context_summary_df.csv\", index=False)\n",
    "# loss_file = \"./artifacts/large_context_losses.json\"\n",
    "\n",
    "with open(loss_file, \"w\") as f:\n",
    "    json.dump(losses_json, f)\n",
    "\n",
    "print_df.droplevel(0, axis=0).dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some handling with pandas to combine the two print_df dataframes\n",
    "# and make it have the same format as the small_context_df and large_context_df\n",
    "\n",
    "small_context_print_df = pd.read_csv(\"./artifacts/small_context_print_df.csv\")\n",
    "large_context_print_df = pd.read_csv(\"./artifacts/large_context_print_df.csv\")\n",
    "\n",
    "large_context_values = large_context_print_df.values\n",
    "\n",
    "# Get the rows from the large_context_df and append them to the small_context_df\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[1]  # for context=30\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[2]  # for context=50\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[3]  # for context=100\n",
    "\n",
    "# Set the columns and their names\n",
    "model_names = ['INP'] * 8 + ['MemoryINP'] * 8 + ['NP']\n",
    "eval_types = ['a', 'ab', 'ac', 'b', 'bc', 'c', 'informed', 'raw'] * 2 + ['raw']\n",
    "\n",
    "columns = pd.MultiIndex.from_arrays([model_names, eval_types], names=['model_name', 'eval_type'])\n",
    "small_context_print_df.columns = columns\n",
    "\n",
    "# The first row contained column names, so remove it\n",
    "small_context_print_df = small_context_print_df.iloc[1:]\n",
    "\n",
    "# Set index to be the context sizes\n",
    "small_context_print_df.index = pd.Index([0, 1, 3, 5, 10, 15, 30, 50, 100], name='num_context')\n",
    "combined_print_df = small_context_print_df\n",
    "\n",
    "combined_print_df = small_context_print_df\n",
    "\n",
    "combined_print_df.to_csv(\"./artifacts/total_context_print_df.csv\", index=False)\n",
    "combined_print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also do some handling with pandas to combine the two summary_df dataframes\n",
    "small_context_summary_df = pd.read_csv(\"./artifacts/small_context_summary_df.csv\")\n",
    "large_context_summary_df = pd.read_csv(\"./artifacts/large_context_summary_df.csv\")\n",
    "\n",
    "combined_summary_df = pd.concat([small_context_summary_df, large_context_summary_df])\n",
    "\n",
    "# Sort by model_name, eval_type, and num_context\n",
    "combined_summary_df = combined_summary_df.sort_values(\n",
    "    by=['model_name', 'eval_type', 'num_context']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "combined_summary_df.to_csv(\"./artifacts/total_context_summary_df.csv\", index=False)\n",
    "\n",
    "combined_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two losses json files in a single dictionary\n",
    "small_context_losses_path = \"./artifacts/small_context_losses.json\"\n",
    "large_context_losses_path = \"./artifacts/large_context_losses.json\"\n",
    "merged_losses_path = \"./artifacts/merged_losses.json\"\n",
    "\n",
    "merged_losses = combine_dictionaries(small_context_losses_path, large_context_losses_path, merged_losses_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was used to generate the log likelihood boxplots for different knowledge types\n",
    "# plot_df = (\n",
    "#     combined_summary_df[\n",
    "#         (combined_summary_df.model_name.isin([\"MemoryINP\", \"INP\", \"NP\"]))\n",
    "#         & (combined_summary_df.eval_type.isin([\"ab\", \"ac\", \"bc\"]))\n",
    "#     ]\n",
    "#     .copy()\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# # Group by model_name and num_context, then calculate mean of \"mean\"\n",
    "# mean_by_model_context = plot_df.groupby(['model_name', 'num_context'])['mean'].mean().reset_index()\n",
    "\n",
    "# # Get rows with eval_type \"raw\" from the original dataframe\n",
    "# raw_rows = combined_summary_df[\n",
    "#     (combined_summary_df.model_name.isin([\"MemoryINP\", \"INP\", \"NP\"])) \n",
    "#     & (combined_summary_df.eval_type == \"raw\")\n",
    "# ].copy()\n",
    "\n",
    "# # Append raw rows to plot_df\n",
    "# plot_df = pd.concat([mean_by_model_context, raw_rows], ignore_index=True)\n",
    "\n",
    "# # Replace NaN values in the Knowledge column with \"one\"\n",
    "# plot_df['eval_type'] = plot_df['eval_type'].fillna('two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (\n",
    "    combined_summary_df[\n",
    "        (combined_summary_df.model_name.isin([\"MemoryINP\", \"INP\", \"NP\"]))\n",
    "        & (combined_summary_df.eval_type.isin([\"raw\", \"a\", \"b\", \"c\"]))\n",
    "    ]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "plot_df[\"mean\"] = -plot_df[\"mean\"]\n",
    "plot_df = plot_df.rename(columns={\"eval_type\": \"Knowledge\", \"model_name\": \"Model\"})\n",
    "plot_df[\"Knowledge\"] = plot_df[\"Knowledge\"].map(\n",
    "    {\n",
    "        \"raw\": r\"$|\\mathcal{K}| = 0$\",\n",
    "        \"two\": r\"$|\\mathcal{K}| = 2$\",\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "sns.lineplot(\n",
    "    plot_df,\n",
    "    x=\"num_context\",\n",
    "    y=\"mean\",\n",
    "    hue=\"Knowledge\",\n",
    "    style=\"Model\",\n",
    "    palette=[\"C2\", \"C4\"],\n",
    "    ax=ax,\n",
    "    style_order=[\"MemoryINP\", \"INP\", \"NP\"],\n",
    "    markers=True,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Log likelihood\")\n",
    "ax.set_xlabel(\"Number of context points\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "labels[0] = \"\"\n",
    "labels[3] = \"\"\n",
    "\n",
    "plt.legend(labels=labels, handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/test_raw_two_k.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta-AUC\n",
    "inp_model = \"INP\"\n",
    "memory_inp_model = \"MemoryINP\"\n",
    "\n",
    "eval_type_ls = [\"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15, 30, 50, 100]\n",
    "\n",
    "inp_auc_summary, _ = get_auc_summary(merged_losses, inp_model, eval_type_ls, num_context_ls)\n",
    "memory_inp_auc_summary, _ = get_auc_summary(merged_losses, memory_inp_model, eval_type_ls, num_context_ls)\n",
    "\n",
    "# Create dataframes for both models\n",
    "inp_df = (pd.DataFrame(inp_auc_summary).T * 100).round(1)\n",
    "inp_df.columns = [\"mean\", \"se\"]\n",
    "inp_df[\"model\"] = \"INP\"\n",
    "\n",
    "memory_df = (pd.DataFrame(memory_inp_auc_summary).T * 100).round(1)\n",
    "memory_df.columns = [\"mean\", \"se\"]\n",
    "memory_df[\"model\"] = \"MemoryINP\"\n",
    "\n",
    "auc_df = pd.concat([inp_df, memory_df])\n",
    "auc_df = auc_df.reset_index().rename(columns={\"index\": \"knowledge_type\"})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "sns.barplot(\n",
    "    data=auc_df,\n",
    "    x=\"knowledge_type\",\n",
    "    y=\"mean\",\n",
    "    hue=\"model\",\n",
    "    ax=ax,\n",
    "    palette=[\"C6\", \"C8\"],\n",
    "    alpha=0.85,\n",
    "    width=0.7,\n",
    ")\n",
    "\n",
    "for i, model in enumerate([\"INP\", \"MemoryINP\"]):\n",
    "    model_data = auc_df[auc_df.model == model]\n",
    "    ax.errorbar(\n",
    "        x=np.arange(len(model_data)) - 0.175 + i*0.35,\n",
    "        y=model_data[\"mean\"],\n",
    "        yerr=model_data[\"se\"],\n",
    "        fmt=\"none\",\n",
    "        c=\"black\",\n",
    "        capsize=3,\n",
    "    )\n",
    "\n",
    "ax.set_ylabel(\"$\\Delta$AUC [\\%]\")\n",
    "ax.set_xlabel(\"Format of $\\mathcal{K}$\")\n",
    "ax.set_xticklabels(\n",
    "    [\"$\\\\{%s\\\\}$\" % \", \".join(list(k)) for k in eval_type_ls], rotation=0\n",
    ")\n",
    "\n",
    "plt.legend(title=\"Model\", loc='upper right', facecolor=\"white\", framealpha=0.8, frameon=True)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./artifacts/delta_auc_barplot.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample predictions for INP\n",
    "for batch in data_loader:\n",
    "    (x_context, y_context), (x_target, y_target), full_knowledge, extras = batch\n",
    "    x_context = x_context.to(config.device)\n",
    "    y_context = y_context.to(config.device)\n",
    "    x_target = x_target.to(config.device)\n",
    "    y_target = y_target.to(config.device)\n",
    "\n",
    "\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15, 30]\n",
    "sample_idx = np.random.choice(list(range(x_target.shape[-2])), max(num_context_ls))\n",
    "batch_idx = 0\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(num_context_ls), 7, figsize=(15, 9), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "colors = {\"raw\": \"grey\", \"a\": \"C1\", \"b\": \"C2\", \"c\": \"C3\", \"ab\": \"C4\", \"ac\": \"C5\", \"bc\": \"C6\"}\n",
    "\n",
    "titles = [\n",
    "    \"$\\mathcal{K} = \\emptyset$\", \n",
    "    \"$\\mathcal{K} = \\{a\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b,c\\}$\"\n",
    "]\n",
    "for ax, title in zip(axs[0], titles):\n",
    "    ax.set_title(title)\n",
    "\n",
    "y_labels = [\n",
    "    \"$N_c = 0$\",\n",
    "    \"$N_c = 1$\", \n",
    "    \"$N_c = 3$\",\n",
    "    \"$N_c = 5$\",\n",
    "    \"$N_c = 10$\",\n",
    "    \"$N_c = 15$\",\n",
    "    \"$N_c = 30$\"\n",
    "]\n",
    "for ax, label in zip(axs[:,0], y_labels):\n",
    "    ax.set_ylabel(label)\n",
    "\n",
    "\n",
    "for j, knowledge_type in enumerate([\"raw\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]):\n",
    "    if knowledge_type == \"raw\":\n",
    "        knowledge = None\n",
    "    else:\n",
    "        mask = get_mask(knowledge_type)\n",
    "        knowledge = full_knowledge * mask\n",
    "\n",
    "    for i, num_context in enumerate(num_context_ls):\n",
    "        x_context = x_target[:, sample_idx[:num_context], :]\n",
    "        y_context = y_target[:, sample_idx[:num_context], :]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            INP_outputs = model_dict[\"INP\"](\n",
    "                x_context, y_context, x_target, y_target=y_target, knowledge=knowledge\n",
    "            )\n",
    "\n",
    "        plot_predictions(\n",
    "            axs[i][j],\n",
    "            batch_idx,\n",
    "            INP_outputs,\n",
    "            x_context,\n",
    "            y_context,\n",
    "            x_target,\n",
    "            extras,\n",
    "            color=colors[knowledge_type],\n",
    "            plot_true=True,\n",
    "        )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/inp_predictions.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample predictions for MemoryINP\n",
    "fig, axs = plt.subplots(\n",
    "    len(num_context_ls), 7, figsize=(15, 9), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "colors = {\"raw\": \"grey\", \"a\": \"C1\", \"b\": \"C2\", \"c\": \"C3\", \"ab\": \"C4\", \"ac\": \"C5\", \"bc\": \"C6\"}\n",
    "\n",
    "titles = [\n",
    "    \"$\\mathcal{K} = \\emptyset$\", \n",
    "    \"$\\mathcal{K} = \\{a\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b,c\\}$\"\n",
    "]\n",
    "for ax, title in zip(axs[0], titles):\n",
    "    ax.set_title(title)\n",
    "\n",
    "y_labels = [\n",
    "    \"$N_c = 0$\",\n",
    "    \"$N_c = 1$\", \n",
    "    \"$N_c = 3$\",\n",
    "    \"$N_c = 5$\",\n",
    "    \"$N_c = 10$\",\n",
    "    \"$N_c = 15$\",\n",
    "    \"$N_c = 30$\"\n",
    "]\n",
    "for ax, label in zip(axs[:,0], y_labels):\n",
    "    ax.set_ylabel(label)\n",
    "\n",
    "\n",
    "for j, knowledge_type in enumerate([\"raw\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]):\n",
    "    if knowledge_type == \"raw\":\n",
    "        knowledge = None\n",
    "    else:\n",
    "        mask = get_mask(knowledge_type)\n",
    "        knowledge = full_knowledge * mask\n",
    "\n",
    "    for i, num_context in enumerate(num_context_ls):\n",
    "        x_context = x_target[:, sample_idx[:num_context], :]\n",
    "        y_context = y_target[:, sample_idx[:num_context], :]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            MemoryINP_outputs = model_dict[\"MemoryINP\"](\n",
    "                x_context, y_context, x_target, y_target=y_target, knowledge=knowledge\n",
    "            )\n",
    "\n",
    "        plot_predictions(\n",
    "            axs[i][j],\n",
    "            batch_idx,\n",
    "            MemoryINP_outputs,\n",
    "            x_context,\n",
    "            y_context,\n",
    "            x_target,\n",
    "            extras,\n",
    "            color=colors[knowledge_type],\n",
    "            plot_true=True,\n",
    "        )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/memory_inp_predictions.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "\n",
    "uncertainties_inp = get_uncertainties(\n",
    "    outputs_dict, num_context_ls, knowledge_type_ls, model_name=\"INP\", n_batches=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "\n",
    "uncertainties_memory_inp = get_uncertainties(\n",
    "    outputs_dict, num_context_ls, knowledge_type_ls, model_name=\"MemoryINP\", n_batches=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent differences between raw and other knowledge types\n",
    "differences = {}\n",
    "for num_context in num_context_ls:\n",
    "    differences[num_context] = {}\n",
    "    for knowledge_type in knowledge_type_ls[1:]:\n",
    "        if knowledge_type == 'informed':\n",
    "            continue\n",
    "        differences[num_context][f'raw-{knowledge_type}'] = {}\n",
    "        for batch_idx in uncertainties_memory_inp[num_context]['raw'].keys():\n",
    "            differences[num_context][f'raw-{knowledge_type}'][batch_idx] = {}\n",
    "            for uncert_type in uncertainties_memory_inp[num_context]['raw'][batch_idx].keys():\n",
    "                raw_uncert = uncertainties_memory_inp[num_context]['raw'][batch_idx][uncert_type]\n",
    "                other_uncert = uncertainties_memory_inp[num_context][knowledge_type][batch_idx][uncert_type]\n",
    "                # Calculate percent difference: (raw - other)/raw * 100\n",
    "                differences[num_context][f'raw-{knowledge_type}'][batch_idx][uncert_type] = ((raw_uncert - other_uncert) / raw_uncert) * 100\n",
    "\n",
    "# Create boxplots for all knowledge type differences\n",
    "data_lists = {}\n",
    "for diff_type in differences[0].keys():\n",
    "    data_lists[diff_type] = []\n",
    "    for batch_idx in differences[0][diff_type].keys():\n",
    "        data_lists[diff_type].append(differences[0][diff_type][batch_idx]['epistemic'].mean())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot_labels = [r'\\{a\\}', r'\\{b\\}', r'\\{c\\}', r'\\{a,b\\}', r'\\{a,c\\}', r'\\{b,c\\}']\n",
    "bp = plt.boxplot([data_lists[k] for k in data_lists.keys()], labels=boxplot_labels, patch_artist=True)\n",
    "\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('olive')\n",
    "    patch.set_alpha(0.7)\n",
    "    patch.set_edgecolor('black')\n",
    "\n",
    "plt.setp(bp['whiskers'], color='black')\n",
    "plt.setp(bp['caps'], color='black')\n",
    "plt.setp(bp['medians'], color='black')\n",
    "\n",
    "plt.title('Reduction in epistemic uncertainty')\n",
    "plt.ylabel('Mean Uncertainty Percent Difference')\n",
    "plt.xlabel(r'Format of $\\mathcal{K}$')\n",
    "plt.grid(axis='x')\n",
    "plt.ylim(0, 8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/uncertainty_reduction_boxplot.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation study for MemoryINP: With and without memory\n",
    "\n",
    "# Load the models\n",
    "save_dirs = {\n",
    "    \"with_memory\": \"../saves/INPs_sinusoids/memory_inp_abc2\",\n",
    "    \"without_memory\": \"../saves/INPs_sinusoids/no_memory\",\n",
    "}\n",
    "\n",
    "models = list(save_dirs.keys())\n",
    "model_dict = {}\n",
    "config_dict = {}\n",
    "\n",
    "for model_name, save_dir in save_dirs.items():\n",
    "    model_dict[model_name], config_dict[model_name] = load_memory_inp_model(\n",
    "        save_dir, load_it=\"best\"\n",
    "    )\n",
    "    model_dict[model_name].eval()\n",
    "\n",
    "model_names = list(model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataloaders\n",
    "config = Namespace(\n",
    "    min_num_context=0,\n",
    "    max_num_context=100,\n",
    "    num_targets=100,\n",
    "    noise=0.2,\n",
    "    batch_size=32,\n",
    "    x_sampler=\"uniform\",\n",
    "    test_num_z_samples=32,\n",
    "    dataset=\"set-trending-sinusoids\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "dataset = SetKnowledgeTrendingSinusoids(\n",
    "    root=\"../data/trending-sinusoids\", split=\"test\", knowledge_type=\"full\"\n",
    ")\n",
    "data_loader = get_dataloader(dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models on different knowledge types\n",
    "eval_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"bc\", \"ac\"]\n",
    "\n",
    "# # 1st run\n",
    "# num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "\n",
    "# 2nd run\n",
    "num_context_ls = [30, 50, 100]\n",
    "\n",
    "summary_df, losses, outputs_dict = get_summary_df(\n",
    "    model_dict, config_dict, data_loader, eval_type_ls, model_names, num_context_ls\n",
    ")\n",
    "\n",
    "summary_df[\"print_value\"] = summary_df[\"mean\"].apply(\n",
    "    lambda x: f\"{x:.1f}\"\n",
    ")\n",
    "print_df = (\n",
    "    summary_df.dropna(subset=[\"mean\"])\n",
    "    .pivot(\n",
    "        columns=\"num_context\", index=[\"model_name\", \"eval_type\"], values=[\"print_value\"]\n",
    "    )\n",
    "    .T.round(2)\n",
    ")\n",
    "\n",
    "# Convert losses to a format that can be serialized to JSON\n",
    "losses_json = {}\n",
    "for model_name, model_losses in losses.items():\n",
    "    losses_json[model_name] = {}\n",
    "    for eval_type, eval_losses in model_losses.items():\n",
    "        losses_json[model_name][eval_type] = {}\n",
    "        for num_context, context_losses in eval_losses.items():\n",
    "            # Convert tensor lists to regular lists of floats\n",
    "            losses_json[model_name][eval_type][num_context] = [\n",
    "                loss.cpu().numpy().tolist() for loss in context_losses\n",
    "            ]\n",
    "\n",
    "# # 1st run\n",
    "# print_df.to_csv(\"./artifacts/with_without_memory_small_context_print_df.csv\", index=False)\n",
    "# summary_df.to_csv(\"./artifacts/with_without_memory_small_context_summary_df.csv\", index=False)\n",
    "# loss_file = \"./artifacts/with_without_memory_small_context_losses.json\"\n",
    "\n",
    "# 2nd run\n",
    "print_df.to_csv(\"./artifacts/with_without_memory_large_context_print_df.csv\", index=False)\n",
    "summary_df.to_csv(\"./artifacts/with_without_memory_large_context_summary_df.csv\", index=False)\n",
    "loss_file = \"./artifacts/with_without_memory_large_context_losses.json\"\n",
    "\n",
    "with open(loss_file, \"w\") as f:\n",
    "    json.dump(losses_json, f)\n",
    "\n",
    "print_df.droplevel(0, axis=0).dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some handling with pandas to combine the two print_df dataframes\n",
    "\n",
    "small_context_print_df = pd.read_csv(\"./artifacts/with_without_memory_small_context_print_df.csv\")\n",
    "large_context_print_df = pd.read_csv(\"./artifacts/with_without_memory_large_context_print_df.csv\")\n",
    "\n",
    "large_context_values = large_context_print_df.values\n",
    "\n",
    "# Get the rows from the large_context_df and append them to the small_context_df\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[1]  # for context=30\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[2]  # for context=50\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[3]  # for context=100\n",
    "\n",
    "# Set the columns and their names\n",
    "model_names = ['with_memory'] * 8 + ['without_memory'] * 8\n",
    "eval_types = ['a', 'ab', 'ac', 'b', 'bc', 'c', 'informed', 'raw'] * 2\n",
    "\n",
    "columns = pd.MultiIndex.from_arrays([model_names, eval_types], names=['model_name', 'eval_type'])\n",
    "small_context_print_df.columns = columns\n",
    "\n",
    "# The first row contained column names, so remove it\n",
    "small_context_print_df = small_context_print_df.iloc[1:]\n",
    "\n",
    "# Set index to be the context sizes\n",
    "small_context_print_df.index = pd.Index([0, 1, 3, 5, 10, 15, 30, 50, 100], name='num_context')\n",
    "combined_print_df = small_context_print_df\n",
    "\n",
    "combined_print_df.to_csv(\"./artifacts/with_without_memory_total_context_print_df.csv\", index=False)\n",
    "\n",
    "combined_print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also do some handling with pandas to combine the two summary_df dataframes\n",
    "small_context_summary_df = pd.read_csv(\"./artifacts/with_without_memory_small_context_summary_df.csv\")\n",
    "large_context_summary_df = pd.read_csv(\"./artifacts/with_without_memory_large_context_summary_df.csv\")\n",
    "\n",
    "combined_summary_df = pd.concat([small_context_summary_df, large_context_summary_df])\n",
    "\n",
    "# Sort by model_name, eval_type, and num_context\n",
    "combined_summary_df = combined_summary_df.sort_values(\n",
    "    by=['model_name', 'eval_type', 'num_context']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "combined_summary_df.to_csv(\"./artifacts/with_without_memory_total_context_summary_df.csv\", index=False)\n",
    "\n",
    "combined_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two losses json files in a single dictionary\n",
    "small_context_losses_path = \"./artifacts/with_without_memory_small_context_losses.json\"\n",
    "large_context_losses_path = \"./artifacts/with_without_memory_large_context_losses.json\"\n",
    "merged_losses_path = \"./artifacts/with_without_memory_total_context_losses.json\"\n",
    "\n",
    "merged_losses = combine_dictionaries(small_context_losses_path, large_context_losses_path, merged_losses_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (\n",
    "    combined_summary_df[\n",
    "        (combined_summary_df.model_name.isin([\"with_memory\", \"without_memory\"]))\n",
    "        & (combined_summary_df.eval_type.isin([\"raw\", \"informed\"]))\n",
    "    ]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "plot_df[\"mean\"] = -plot_df[\"mean\"]\n",
    "plot_df = plot_df.rename(columns={\"eval_type\": \"Knowledge\", \"model_name\": \"Model\"})\n",
    "plot_df[\"Knowledge\"] = plot_df[\"Knowledge\"].map(\n",
    "    {\n",
    "        \"raw\": r\"$\\mathcal{K} = \\emptyset$\",\n",
    "        \"informed\": r\"$\\mathcal{K} \\neq \\emptyset$\",\n",
    "    }\n",
    ")\n",
    "\n",
    "plot_df[\"Model\"] = plot_df[\"Model\"].map({\n",
    "    \"with_memory\": \"MemoryINP w/ memory\",\n",
    "    \"without_memory\": \"MemoryINP w/o memory\"\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "sns.lineplot(\n",
    "    plot_df,\n",
    "    x=\"num_context\",\n",
    "    y=\"mean\",\n",
    "    hue=\"Knowledge\",\n",
    "    style=\"Model\",\n",
    "    palette=[\"C2\", \"C4\"],\n",
    "    ax=ax,\n",
    "    style_order=[\"MemoryINP w/ memory\", \"MemoryINP w/o memory\"],\n",
    "    markers=True,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Log likelihood\")\n",
    "ax.set_xlabel(\"Number of context points\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "labels[0] = \"\"\n",
    "labels[3] = \"\"\n",
    "\n",
    "plt.legend(labels=labels, handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/with_without_memory_log_likelihood.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../saves/INPs_sinusoids/memory_slots_16\n",
      "../saves/INPs_sinusoids/memory_slots_32\n",
      "../saves/INPs_sinusoids/memory_inp_abc2_0\n",
      "../saves/INPs_sinusoids/memory_slots_128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsoump/memory-informed-meta-learning/evaluation/utils.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"{save_dir}/model_{load_it}.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Ablation study for MemoryINP: # memory slots\n",
    "\n",
    "# Load the models\n",
    "save_dirs = {\n",
    "    \"memory_slots_16\": \"../saves/INPs_sinusoids/memory_slots_16\",\n",
    "    \"memory_slots_32\": \"../saves/INPs_sinusoids/memory_slots_32\",\n",
    "    \"memory_slots_64\": \"../saves/INPs_sinusoids/memory_inp_abc2_0\",\n",
    "    \"memory_slots_128\": \"../saves/INPs_sinusoids/memory_slots_128\",\n",
    "}\n",
    "\n",
    "models = list(save_dirs.keys())\n",
    "model_dict = {}\n",
    "config_dict = {}\n",
    "\n",
    "for model_name, save_dir in save_dirs.items():\n",
    "    model_dict[model_name], config_dict[model_name] = load_memory_inp_model(\n",
    "        save_dir, load_it=\"best\"\n",
    "    )\n",
    "    model_dict[model_name].eval()\n",
    "\n",
    "model_names = list(model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataloaders\n",
    "config = Namespace(\n",
    "    min_num_context=0,\n",
    "    max_num_context=100,\n",
    "    num_targets=100,\n",
    "    noise=0.2,\n",
    "    batch_size=32,\n",
    "    x_sampler=\"uniform\",\n",
    "    test_num_z_samples=32,\n",
    "    dataset=\"set-trending-sinusoids\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "dataset = SetKnowledgeTrendingSinusoids(\n",
    "    root=\"../data/trending-sinusoids\", split=\"test\", knowledge_type=\"full\"\n",
    ")\n",
    "data_loader = get_dataloader(dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"bc\", \"ac\"]\n",
    "\n",
    "num_context_ls = [30]\n",
    "\n",
    "summary_df, losses, outputs_dict = get_summary_df(\n",
    "    model_dict, config_dict, data_loader, eval_type_ls, model_names, num_context_ls\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"print_value\"] = summary_df[\"mean\"].apply(\n",
    "    lambda x: f\"{x:.1f}\"\n",
    ")\n",
    "print_df = (\n",
    "    summary_df.dropna(subset=[\"mean\"])\n",
    "    .pivot(\n",
    "        columns=\"num_context\", index=[\"model_name\", \"eval_type\"], values=[\"print_value\"]\n",
    "    )\n",
    "    .T.round(2)\n",
    ")\n",
    "\n",
    "print_df = print_df.droplevel(0, axis=0).dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th colspan=\"2\" halign=\"left\">memory_slots_128</th>\n",
       "      <th colspan=\"2\" halign=\"left\">memory_slots_16</th>\n",
       "      <th colspan=\"2\" halign=\"left\">memory_slots_32</th>\n",
       "      <th colspan=\"2\" halign=\"left\">memory_slots_64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_type</th>\n",
       "      <th>informed</th>\n",
       "      <th>raw</th>\n",
       "      <th>informed</th>\n",
       "      <th>raw</th>\n",
       "      <th>informed</th>\n",
       "      <th>raw</th>\n",
       "      <th>informed</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_context</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-7.4</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_name  memory_slots_128       memory_slots_16       memory_slots_32  \\\n",
       "eval_type           informed   raw        informed   raw        informed   \n",
       "num_context                                                                \n",
       "30                      -7.4  -5.1            -2.3  -2.9            -7.1   \n",
       "\n",
       "model_name        memory_slots_64        \n",
       "eval_type     raw        informed   raw  \n",
       "num_context                              \n",
       "30           -3.6           -11.0  -8.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for only 'informed' and 'raw' eval types\n",
    "filtered_print_df = print_df.loc[:, (slice(None), ['informed', 'raw'])]\n",
    "filtered_print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw = [2.9, 3.6, 8.7, 5.1]\n",
    "informed = [2.3, 7.1, 10.6, 7.4]\n",
    "\n",
    "# Create DataFrame for seaborn\n",
    "data = pd.DataFrame({\n",
    "    'Memory Slots': ['16']*2 + ['32']*2 + ['64']*2 + ['128']*2,\n",
    "    'Type': ['Raw', 'Informed']*4,\n",
    "    'Value': [raw[0], informed[0], raw[1], informed[1], raw[2], informed[2], raw[3], informed[3]]\n",
    "})\n",
    "\n",
    "data[\"Type\"] = data[\"Type\"].map(\n",
    "    {\n",
    "        \"Raw\": r\"$\\mathcal{K} = \\emptyset$\",\n",
    "        \"Informed\": r\"$\\mathcal{K} \\neq \\emptyset$\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "# Create plot using seaborn\n",
    "ax = sns.barplot(\n",
    "    data=data,\n",
    "    x='Memory Slots',\n",
    "    y='Value',\n",
    "    hue='Type',\n",
    "    palette=['C2', 'C4']\n",
    ")\n",
    "\n",
    "plt.ylabel('Log likelihood')\n",
    "\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    if bar.get_height() != 0:  # Only add text if height is not 0\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2,\n",
    "            bar.get_height(),\n",
    "            f'{bar.get_height():.1f}',\n",
    "            ha='center',\n",
    "            va='bottom'\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/memory_slots_log_likelihood.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-modulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
