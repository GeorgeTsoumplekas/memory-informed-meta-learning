{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsoump/memory-informed-meta-learning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import load_inp_model, load_memory_inp_model, get_mask\n",
    "import sys\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import json\n",
    "\n",
    "from dataset.dataset import *\n",
    "from dataset.utils import get_dataloader\n",
    "from evaluation.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Dark2\")\n",
    "\n",
    "plt.rcParams[\"text.latex.preamble\"] = (\n",
    "    \"\\\\usepackage{lmodern} \\\\usepackage{times} \\\\usepackage{amssymb}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../saves/INPs_sinusoids/np_0\n",
      "../saves/INPs_sinusoids/inp_abc2_0\n",
      "../saves/INPs_sinusoids/memory_inp_abc2_57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsoump/memory-informed-meta-learning/evaluation/utils.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"{save_dir}/model_{load_it}.pt\")\n",
      "/home/tsoump/memory-informed-meta-learning/evaluation/utils.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"{save_dir}/model_{load_it}.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Load the models\n",
    "save_dirs = {\n",
    "    \"NP\": \"../saves/INPs_sinusoids/np_0\",\n",
    "    \"INP\": \"../saves/INPs_sinusoids/inp_abc2_0\",\n",
    "    \"MemoryINP\": \"../saves/INPs_sinusoids/memory_inp_abc2_57\",\n",
    "}\n",
    "\n",
    "models = list(save_dirs.keys())\n",
    "model_dict = {}\n",
    "config_dict = {}\n",
    "\n",
    "for model_name, save_dir in save_dirs.items():\n",
    "    if model_name == \"MemoryINP\":\n",
    "        model_dict[model_name], config_dict[model_name] = load_memory_inp_model(\n",
    "            save_dir, load_it=\"best\"\n",
    "        )\n",
    "    else:\n",
    "        model_dict[model_name], config_dict[model_name] = load_inp_model(\n",
    "            save_dir, load_it=\"best\"\n",
    "        )\n",
    "    model_dict[model_name].eval()\n",
    "\n",
    "model_names = list(model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataloaders\n",
    "config = Namespace(\n",
    "    min_num_context=0,\n",
    "    max_num_context=100,\n",
    "    num_targets=100,\n",
    "    noise=0.2,\n",
    "    batch_size=32,\n",
    "    x_sampler=\"uniform\",\n",
    "    test_num_z_samples=32,\n",
    "    dataset=\"set-trending-sinusoids\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "dataset = SetKnowledgeTrendingSinusoids(\n",
    "    root=\"../data/trending-sinusoids\", split=\"test\", knowledge_type=\"full\"\n",
    ")\n",
    "data_loader = get_dataloader(dataset, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Important**: Due to lack of memory of VRAM (8gb available) I have to compute the summary_df table in two steps:\n",
    "1. Compute the summary_df table for smaller context sets [0, 1, 3, 5, 10, 15]\n",
    "2. Compute the summary_df table for larger context sets [30, 50, 100]\n",
    "\n",
    "To do this: \n",
    "\n",
    "1. First uncomment the first num_context_ls and the corresponding .to_csv() lines and run the cell.\n",
    "2. Then restart kernel and run the cell again with the second num_context_ls uncommented and the corresponding .to_csv() lines.\n",
    "3. After that continue with the rest of the code that combines the two saved summary_df into a unified one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models on different knowledge types\n",
    "eval_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"bc\", \"ac\"]\n",
    "\n",
    "# 1st run\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "\n",
    "# # 2nd run\n",
    "# num_context_ls = [30, 50, 100]\n",
    "\n",
    "if not os.path.exists(\"./artifacts\"):\n",
    "    os.makedirs(\"./artifacts\")\n",
    "\n",
    "\n",
    "summary_df, losses, outputs_dict = get_summary_df(\n",
    "    model_dict, config_dict, data_loader, eval_type_ls, model_names, num_context_ls\n",
    ")\n",
    "\n",
    "summary_df[\"print_value\"] = summary_df[\"mean\"].apply(\n",
    "    lambda x: f\"{x:.1f}\"\n",
    ")\n",
    "print_df = (\n",
    "    summary_df.dropna(subset=[\"mean\"])\n",
    "    .pivot(\n",
    "        columns=\"num_context\", index=[\"model_name\", \"eval_type\"], values=[\"print_value\"]\n",
    "    )\n",
    "    .T.round(2)\n",
    ")\n",
    "\n",
    "# Convert losses to a format that can be serialized to JSON\n",
    "losses_json = {}\n",
    "for model_name, model_losses in losses.items():\n",
    "    losses_json[model_name] = {}\n",
    "    for eval_type, eval_losses in model_losses.items():\n",
    "        losses_json[model_name][eval_type] = {}\n",
    "        for num_context, context_losses in eval_losses.items():\n",
    "            # Convert tensor lists to regular lists of floats\n",
    "            losses_json[model_name][eval_type][num_context] = [\n",
    "                loss.cpu().numpy().tolist() for loss in context_losses\n",
    "            ]\n",
    "\n",
    "# 1st run\n",
    "print_df.to_csv(\"./artifacts/small_context_print_df.csv\", index=False)\n",
    "summary_df.to_csv(\"./artifacts/small_context_summary_df.csv\", index=False)\n",
    "loss_file = \"./artifacts/small_context_losses.json\"\n",
    "\n",
    "# # 2nd run\n",
    "# print_df.to_csv(\"./artifacts/large_context_print_df.csv\", index=False)\n",
    "# summary_df.to_csv(\"./artifacts/large_context_summary_df.csv\", index=False)\n",
    "# loss_file = \"./artifacts/large_context_losses.json\"\n",
    "\n",
    "with open(loss_file, \"w\") as f:\n",
    "    json.dump(losses_json, f)\n",
    "\n",
    "print_df.droplevel(0, axis=0).dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some handling with pandas to combine the two print_df dataframes\n",
    "# and make it have the same format as the small_context_df and large_context_df\n",
    "\n",
    "small_context_print_df = pd.read_csv(\"./artifacts/small_context_print_df.csv\")\n",
    "large_context_print_df = pd.read_csv(\"./artifacts/large_context_print_df.csv\")\n",
    "\n",
    "large_context_values = large_context_print_df.values\n",
    "\n",
    "# Get the rows from the large_context_df and append them to the small_context_df\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[1]  # for context=30\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[2]  # for context=50\n",
    "small_context_print_df.loc[len(small_context_print_df)] = large_context_values[3]  # for context=100\n",
    "\n",
    "# Set the columns and their names\n",
    "model_names = ['INP'] * 8 + ['MemoryINP'] * 8 + ['NP']\n",
    "eval_types = ['a', 'ab', 'ac', 'b', 'bc', 'c', 'informed', 'raw'] * 2 + ['raw']\n",
    "\n",
    "columns = pd.MultiIndex.from_arrays([model_names, eval_types], names=['model_name', 'eval_type'])\n",
    "small_context_print_df.columns = columns\n",
    "\n",
    "# The first row contained column names, so remove it\n",
    "small_context_print_df = small_context_print_df.iloc[1:]\n",
    "\n",
    "# Set index to be the context sizes\n",
    "small_context_print_df.index = pd.Index([0, 1, 3, 5, 10, 15, 30, 50, 100], name='num_context')\n",
    "combined_print_df = small_context_print_df\n",
    "\n",
    "combined_print_df = small_context_print_df\n",
    "\n",
    "combined_print_df.to_csv(\"./artifacts/total_context_print_df.csv\", index=False)\n",
    "\n",
    "combined_print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also do some handling with pandas to combine the two summary_df dataframes\n",
    "small_context_summary_df = pd.read_csv(\"./artifacts/small_context_summary_df.csv\")\n",
    "large_context_summary_df = pd.read_csv(\"./artifacts/large_context_summary_df.csv\")\n",
    "\n",
    "combined_summary_df = pd.concat([small_context_summary_df, large_context_summary_df])\n",
    "\n",
    "# Sort by model_name, eval_type, and num_context\n",
    "combined_summary_df = combined_summary_df.sort_values(\n",
    "    by=['model_name', 'eval_type', 'num_context']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "combined_summary_df.to_csv(\"./artifacts/total_context_summary_df.csv\", index=False)\n",
    "\n",
    "combined_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two losses json files in a single dictionary\n",
    "small_context_losses_path = \"./artifacts/small_context_losses.json\"\n",
    "large_context_losses_path = \"./artifacts/large_context_losses.json\"\n",
    "merged_losses_path = \"./artifacts/merged_losses.json\"\n",
    "\n",
    "merged_losses = combine_dictionaries(small_context_losses_path, large_context_losses_path, merged_losses_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was used to generate the log likelihood boxplots for different knowledge types\n",
    "# plot_df = (\n",
    "#     combined_summary_df[\n",
    "#         (combined_summary_df.model_name.isin([\"MemoryINP\", \"INP\", \"NP\"]))\n",
    "#         & (combined_summary_df.eval_type.isin([\"ab\", \"ac\", \"bc\"]))\n",
    "#     ]\n",
    "#     .copy()\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# # Group by model_name and num_context, then calculate mean of \"mean\"\n",
    "# mean_by_model_context = plot_df.groupby(['model_name', 'num_context'])['mean'].mean().reset_index()\n",
    "\n",
    "# # Get rows with eval_type \"raw\" from the original dataframe\n",
    "# raw_rows = combined_summary_df[\n",
    "#     (combined_summary_df.model_name.isin([\"MemoryINP\", \"INP\", \"NP\"])) \n",
    "#     & (combined_summary_df.eval_type == \"raw\")\n",
    "# ].copy()\n",
    "\n",
    "# # Append raw rows to plot_df\n",
    "# plot_df = pd.concat([mean_by_model_context, raw_rows], ignore_index=True)\n",
    "\n",
    "# # Replace NaN values in the Knowledge column with \"one\"\n",
    "# plot_df['eval_type'] = plot_df['eval_type'].fillna('two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (\n",
    "    combined_summary_df[\n",
    "        (combined_summary_df.model_name.isin([\"MemoryINP\", \"INP\", \"NP\"]))\n",
    "        & (combined_summary_df.eval_type.isin([\"raw\", \"a\", \"b\", \"c\"]))\n",
    "    ]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "plot_df[\"mean\"] = -plot_df[\"mean\"]\n",
    "plot_df = plot_df.rename(columns={\"eval_type\": \"Knowledge\", \"model_name\": \"Model\"})\n",
    "plot_df[\"Knowledge\"] = plot_df[\"Knowledge\"].map(\n",
    "    {\n",
    "        \"raw\": r\"$|\\mathcal{K}| = 0$\",\n",
    "        \"two\": r\"$|\\mathcal{K}| = 2$\",\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "sns.lineplot(\n",
    "    plot_df,\n",
    "    x=\"num_context\",\n",
    "    y=\"mean\",\n",
    "    hue=\"Knowledge\",\n",
    "    style=\"Model\",\n",
    "    palette=[\"C2\", \"C4\"],\n",
    "    ax=ax,\n",
    "    style_order=[\"MemoryINP\", \"INP\", \"NP\"],\n",
    "    markers=True,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Log likelihood\")\n",
    "ax.set_xlabel(\"Number of context points\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "labels[0] = \"\"\n",
    "labels[3] = \"\"\n",
    "\n",
    "plt.legend(labels=labels, handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/test_raw_two_k.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta-AUC\n",
    "inp_model = \"INP\"\n",
    "memory_inp_model = \"MemoryINP\"\n",
    "\n",
    "eval_type_ls = [\"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15, 30, 50, 100]\n",
    "\n",
    "inp_auc_summary, _ = get_auc_summary(merged_losses, inp_model, eval_type_ls, num_context_ls)\n",
    "memory_inp_auc_summary, _ = get_auc_summary(merged_losses, memory_inp_model, eval_type_ls, num_context_ls)\n",
    "\n",
    "# Create dataframes for both models\n",
    "inp_df = (pd.DataFrame(inp_auc_summary).T * 100).round(1)\n",
    "inp_df.columns = [\"mean\", \"se\"]\n",
    "inp_df[\"model\"] = \"INP\"\n",
    "\n",
    "memory_df = (pd.DataFrame(memory_inp_auc_summary).T * 100).round(1)\n",
    "memory_df.columns = [\"mean\", \"se\"]\n",
    "memory_df[\"model\"] = \"MemoryINP\"\n",
    "\n",
    "auc_df = pd.concat([inp_df, memory_df])\n",
    "auc_df = auc_df.reset_index().rename(columns={\"index\": \"knowledge_type\"})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "sns.barplot(\n",
    "    data=auc_df,\n",
    "    x=\"knowledge_type\",\n",
    "    y=\"mean\",\n",
    "    hue=\"model\",\n",
    "    ax=ax,\n",
    "    palette=[\"C6\", \"C8\"],\n",
    "    alpha=0.85,\n",
    "    width=0.7,\n",
    ")\n",
    "\n",
    "for i, model in enumerate([\"INP\", \"MemoryINP\"]):\n",
    "    model_data = auc_df[auc_df.model == model]\n",
    "    ax.errorbar(\n",
    "        x=np.arange(len(model_data)) - 0.175 + i*0.35,\n",
    "        y=model_data[\"mean\"],\n",
    "        yerr=model_data[\"se\"],\n",
    "        fmt=\"none\",\n",
    "        c=\"black\",\n",
    "        capsize=3,\n",
    "    )\n",
    "\n",
    "ax.set_ylabel(\"$\\Delta$AUC [\\%]\")\n",
    "ax.set_xlabel(\"Format of $\\mathcal{K}$\")\n",
    "ax.set_xticklabels(\n",
    "    [\"$\\\\{%s\\\\}$\" % \", \".join(list(k)) for k in eval_type_ls], rotation=0\n",
    ")\n",
    "\n",
    "plt.legend(title=\"Model\", loc='upper right', facecolor=\"white\", framealpha=0.8, frameon=True)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./artifacts/delta_auc_barplot.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample predictions for INP\n",
    "for batch in data_loader:\n",
    "    (x_context, y_context), (x_target, y_target), full_knowledge, extras = batch\n",
    "    x_context = x_context.to(config.device)\n",
    "    y_context = y_context.to(config.device)\n",
    "    x_target = x_target.to(config.device)\n",
    "    y_target = y_target.to(config.device)\n",
    "\n",
    "\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15, 30]\n",
    "sample_idx = np.random.choice(list(range(x_target.shape[-2])), max(num_context_ls))\n",
    "batch_idx = 0\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(num_context_ls), 7, figsize=(15, 9), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "colors = {\"raw\": \"grey\", \"a\": \"C1\", \"b\": \"C2\", \"c\": \"C3\", \"ab\": \"C4\", \"ac\": \"C5\", \"bc\": \"C6\"}\n",
    "\n",
    "titles = [\n",
    "    \"$\\mathcal{K} = \\emptyset$\", \n",
    "    \"$\\mathcal{K} = \\{a\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b,c\\}$\"\n",
    "]\n",
    "for ax, title in zip(axs[0], titles):\n",
    "    ax.set_title(title)\n",
    "\n",
    "y_labels = [\n",
    "    \"$N_c = 0$\",\n",
    "    \"$N_c = 1$\", \n",
    "    \"$N_c = 3$\",\n",
    "    \"$N_c = 5$\",\n",
    "    \"$N_c = 10$\",\n",
    "    \"$N_c = 15$\",\n",
    "    \"$N_c = 30$\"\n",
    "]\n",
    "for ax, label in zip(axs[:,0], y_labels):\n",
    "    ax.set_ylabel(label)\n",
    "\n",
    "\n",
    "for j, knowledge_type in enumerate([\"raw\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]):\n",
    "    if knowledge_type == \"raw\":\n",
    "        knowledge = None\n",
    "    else:\n",
    "        mask = get_mask(knowledge_type)\n",
    "        knowledge = full_knowledge * mask\n",
    "\n",
    "    for i, num_context in enumerate(num_context_ls):\n",
    "        x_context = x_target[:, sample_idx[:num_context], :]\n",
    "        y_context = y_target[:, sample_idx[:num_context], :]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            INP_outputs = model_dict[\"INP\"](\n",
    "                x_context, y_context, x_target, y_target=y_target, knowledge=knowledge\n",
    "            )\n",
    "\n",
    "        plot_predictions(\n",
    "            axs[i][j],\n",
    "            batch_idx,\n",
    "            INP_outputs,\n",
    "            x_context,\n",
    "            y_context,\n",
    "            x_target,\n",
    "            extras,\n",
    "            color=colors[knowledge_type],\n",
    "            plot_true=True,\n",
    "        )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/inp_predictions.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample predictions for MemoryINP\n",
    "fig, axs = plt.subplots(\n",
    "    len(num_context_ls), 7, figsize=(15, 9), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "colors = {\"raw\": \"grey\", \"a\": \"C1\", \"b\": \"C2\", \"c\": \"C3\", \"ab\": \"C4\", \"ac\": \"C5\", \"bc\": \"C6\"}\n",
    "\n",
    "titles = [\n",
    "    \"$\\mathcal{K} = \\emptyset$\", \n",
    "    \"$\\mathcal{K} = \\{a\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,b\\}$\", \n",
    "    \"$\\mathcal{K} = \\{a,c\\}$\", \n",
    "    \"$\\mathcal{K} = \\{b,c\\}$\"\n",
    "]\n",
    "for ax, title in zip(axs[0], titles):\n",
    "    ax.set_title(title)\n",
    "\n",
    "y_labels = [\n",
    "    \"$N_c = 0$\",\n",
    "    \"$N_c = 1$\", \n",
    "    \"$N_c = 3$\",\n",
    "    \"$N_c = 5$\",\n",
    "    \"$N_c = 10$\",\n",
    "    \"$N_c = 15$\",\n",
    "    \"$N_c = 30$\"\n",
    "]\n",
    "for ax, label in zip(axs[:,0], y_labels):\n",
    "    ax.set_ylabel(label)\n",
    "\n",
    "\n",
    "for j, knowledge_type in enumerate([\"raw\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]):\n",
    "    if knowledge_type == \"raw\":\n",
    "        knowledge = None\n",
    "    else:\n",
    "        mask = get_mask(knowledge_type)\n",
    "        knowledge = full_knowledge * mask\n",
    "\n",
    "    for i, num_context in enumerate(num_context_ls):\n",
    "        x_context = x_target[:, sample_idx[:num_context], :]\n",
    "        y_context = y_target[:, sample_idx[:num_context], :]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            MemoryINP_outputs = model_dict[\"MemoryINP\"](\n",
    "                x_context, y_context, x_target, y_target=y_target, knowledge=knowledge\n",
    "            )\n",
    "\n",
    "        plot_predictions(\n",
    "            axs[i][j],\n",
    "            batch_idx,\n",
    "            MemoryINP_outputs,\n",
    "            x_context,\n",
    "            y_context,\n",
    "            x_target,\n",
    "            extras,\n",
    "            color=colors[knowledge_type],\n",
    "            plot_true=True,\n",
    "        )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/memory_inp_predictions.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "\n",
    "uncertainties_inp = get_uncertainties(\n",
    "    outputs_dict, num_context_ls, knowledge_type_ls, model_name=\"INP\", n_batches=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_type_ls = [\"raw\", \"informed\", \"a\", \"b\", \"c\", \"ab\", \"ac\", \"bc\"]\n",
    "num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "\n",
    "uncertainties_memory_inp = get_uncertainties(\n",
    "    outputs_dict, num_context_ls, knowledge_type_ls, model_name=\"MemoryINP\", n_batches=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent differences between raw and other knowledge types\n",
    "differences = {}\n",
    "for num_context in num_context_ls:\n",
    "    differences[num_context] = {}\n",
    "    for knowledge_type in knowledge_type_ls[1:]:\n",
    "        if knowledge_type == 'informed':\n",
    "            continue\n",
    "        differences[num_context][f'raw-{knowledge_type}'] = {}\n",
    "        for batch_idx in uncertainties_memory_inp[num_context]['raw'].keys():\n",
    "            differences[num_context][f'raw-{knowledge_type}'][batch_idx] = {}\n",
    "            for uncert_type in uncertainties_memory_inp[num_context]['raw'][batch_idx].keys():\n",
    "                raw_uncert = uncertainties_memory_inp[num_context]['raw'][batch_idx][uncert_type]\n",
    "                other_uncert = uncertainties_memory_inp[num_context][knowledge_type][batch_idx][uncert_type]\n",
    "                # Calculate percent difference: (raw - other)/raw * 100\n",
    "                differences[num_context][f'raw-{knowledge_type}'][batch_idx][uncert_type] = ((raw_uncert - other_uncert) / raw_uncert) * 100\n",
    "\n",
    "# Create boxplots for all knowledge type differences\n",
    "data_lists = {}\n",
    "for diff_type in differences[0].keys():\n",
    "    data_lists[diff_type] = []\n",
    "    for batch_idx in differences[0][diff_type].keys():\n",
    "        data_lists[diff_type].append(differences[0][diff_type][batch_idx]['epistemic'].mean())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot_labels = [r'\\{a\\}', r'\\{b\\}', r'\\{c\\}', r'\\{a,b\\}', r'\\{a,c\\}', r'\\{b,c\\}']\n",
    "bp = plt.boxplot([data_lists[k] for k in data_lists.keys()], labels=boxplot_labels, patch_artist=True)\n",
    "\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('olive')\n",
    "    patch.set_alpha(0.7)\n",
    "    patch.set_edgecolor('black')\n",
    "\n",
    "plt.setp(bp['whiskers'], color='black')\n",
    "plt.setp(bp['caps'], color='black')\n",
    "plt.setp(bp['medians'], color='black')\n",
    "\n",
    "plt.title('Reduction in epistemic uncertainty')\n",
    "plt.ylabel('Mean Uncertainty Percent Difference')\n",
    "plt.xlabel(r'Format of $\\mathcal{K}$')\n",
    "plt.grid(axis='x')\n",
    "plt.ylim(0, 8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./artifacts/uncertainty_reduction_boxplot.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-modulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
